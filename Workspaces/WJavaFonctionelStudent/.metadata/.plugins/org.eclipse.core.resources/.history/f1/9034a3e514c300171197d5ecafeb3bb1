
package ch.arc.cours.lamda.i_histo;

import java.util.Arrays;
import java.util.Map;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.stream.Collectors;
import java.util.stream.IntStream;

import ch.arc.cours.material.HistoTools;

public class UseHistogramme
	{

	/*------------------------------------------------------------------*\
	|*							Methodes Public							*|
	\*------------------------------------------------------------------*/

	public static void main(String[] args)
		{
		main();
		}

	public static void main()
		{
		System.out.println("histo : sequentiel to parallel");

		histoStandard();
		histoStreamSequentiel();

		histoStreamParalel1AtomicInteger();
		histoStreamParalel2();
		}

	/*------------------------------------------------------------------*\
	|*							Methodes Private						*|
	\*------------------------------------------------------------------*/

	/**
	 * code standard
	 */
	private static void histoStandard()
		{
		// Input
		int LIMITE = HistoTools.LIMITE;
		int n = LIMITE * 1000;
		int[] tab = HistoTools.createDataInput(n);

		// Output
		int[] histo = new int[LIMITE];

		// init
			{
			for(int s = 0; s < histo.length; s++)
				{
				histo[s] = 0;
				}
			}

		// fill
			{
			for(int s = 0; s < tab.length; s++)
				{
				histo[tab[s]]++;
				}
			}

		// check
		System.out.println("Histo" + Arrays.toString(histo));
		}

	/**
	 * stream sequential
	 */
	private static void histoStreamSequentiel()
		{
		// Input
		int LIMITE = HistoTools.LIMITE;
		int n = LIMITE * 1000;
		int[] tab = HistoTools.createDataInput(n);

		// Output
		int[] histo = new int[LIMITE];

		// init : paralel
		// Indication : stream sur histo, ou stream range [0,n[
		IntStream.range(0, LIMITE).forEach(i -> histo[i] = 0);

		// fill : sequentiel
		// Indication : stream sur histo,
		IntStream.range(0, n).forEach(i -> histo[tab[i]]++);

		// check
		System.out.println("Histo" + Arrays.toString(histo));
		}

	/**
	 * stream parallel AtomicInteger
	 */
	private static void histoStreamParalel1AtomicInteger()
		{
		// Input
		int LIMITE = HistoTools.LIMITE;
		int n = LIMITE * 1000;
		int[] tab = HistoTools.createDataInput(n);

		// Output
		AtomicInteger[] histoAtomic = new AtomicInteger[LIMITE];

		// init
		// Indication : stream range [0,n[
		IntStream.range(0, LIMITE).parallel().forEach(i -> histoAtomic[i] = new AtomicInteger(0));

		//WARNING, SHOULD NOT BE DONE PARALLEL, MULTIPLE VARIABLE MAY NEED TO BE WRITTEN ON THE SAME VALUE e.g. histo[1]
		// fill paralell
		// Indication 1 : stream range tab
		IntStream.range(0, n).boxed().forEach(i -> histoAtomic[tab[i]].set( histoAtomic[tab[i]].get()+1 ));

		// AtomicInteger[] to int[]
		// Indication : mapToInt
		int[] histo = IntStream.range(0, LIMITE).map(i -> histoAtomic[i].get()).toArray();

		// check
		System.out.println("Histo" + Arrays.toString(histo));
		}

	/**
	 * stream parallel sans AtomicInteger
	 */
	private static void histoStreamParalel2()
		{
		// Input
		int LIMITE = HistoTools.LIMITE;
		int n = LIMITE * 1000;
		int[] tab = HistoTools.createDataInput(n);

		// map v1
		// Principe : utiliser une map:
		//					- key :    les valeurs possibles des data (tab)
		//					- valeur : la frequence de la cle
		// Indication 1 : stream sur tab
		// Indication 2 : boxed pour une Stream<Integer>
		// Indication 3 : grouping et counting, soyez malin
		Map<Integer, Long> mapHisto1 = IntStream.range(0, n).parallel().boxed().collect(Collectors.groupingBy(i -> tab[i], Collectors.counting()));

		// map v2
		// Indicatiuon : idem v1 ci-dessus, mais avec Function.identity()
		Map<Integer, Long> mapHisto2 = IntStream.range(0, n).parallel().collect(Collectors.groupingBy(i -> tab[i], Collectors.counting()));

		// TODO
		// to array ie:
		// Map<Integer, Long> to long[]
		long[] histo = new long[LIMITE];
		// Indication 1 : stream sur entrySet
		// Indication 2 : forEach

		// check
		System.out.println("Histo" + Arrays.toString(histo));
		}

	}
